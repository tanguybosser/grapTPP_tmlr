#!/bin/bash
  
#SBATCH --job-name=fnn_short
#SBATCH --output=outputs/fnn_short.out

#SBATCH --cpus-per-task=10
#SBATCH --mem=10G
#SBATCH --gres=gpu:1


##LastFM 

for split in {0..2}
do
python3 -u scripts/train2.py --no-mlflow --dataset 'lastfm_shortcal' --load-from-dir 'data/baseline3' \
--save-results-dir 'results/neurips/lastfm_shortcal' --save-check-dir 'checkpoints/neurips/lastfm_shortcal' \
--eval-metrics True --include-poisson True --patience 50 --batch-size 2 --split $split \
--encoder 'gru' --encoder-encoding 'temporal_with_labels' --encoder-emb-dim 8 --encoder-embedding-constraint 'nonneg' \
--encoder-units-rnn 32 --encoder-layers-rnn 1 --encoder-constraint-rnn 'nonneg' \
--encoder-units-mlp 16 --encoder-activation-mlp 'relu' --encoder-constraint-mlp 'nonneg' \
--decoder 'mlp-cm' --decoder-encoding 'log_times_only' --decoder-emb-dim 8 --decoder-embedding-constraint 'nonneg' \
--decoder-units-mlp 16 --decoder-units-mlp 16 --decoder-activation-mlp 'gumbel_softplus' \
--decoder-activation-final-mlp 'parametric_softplus' --decoder-constraint-mlp 'nonneg' 
done

: "
##MOOC
for split in {0..2}
do
python3 -u scripts/train2.py --no-mlflow --dataset 'mooc_shortcal' --load-from-dir 'data/baseline3' \
--save-results-dir 'results/neurips/mooc_shortcal' --save-check-dir 'checkpoints/neurips/mooc_shortcal' \
--eval-metrics True --include-poisson True --patience 50 --batch-size 32 --split $split \
--encoder 'gru' --encoder-encoding 'temporal_with_labels' --encoder-emb-dim 8 --encoder-embedding-constraint 'nonneg' \
--encoder-units-rnn 32 --encoder-layers-rnn 1 --encoder-constraint-rnn 'nonneg' \
--encoder-units-mlp 16 --encoder-activation-mlp 'relu' --encoder-constraint-mlp 'nonneg' \
--decoder 'mlp-cm' --decoder-encoding 'log_times_only' --decoder-emb-dim 8 --decoder-embedding-constraint 'nonneg' \
--decoder-units-mlp 16 --decoder-units-mlp 16 --decoder-activation-mlp 'gumbel_softplus' \
--decoder-activation-final-mlp 'parametric_softplus' --decoder-constraint-mlp 'nonneg' 
done


##Reddit 

for split in {0..2}
do
python3 -u scripts/train2.py --no-mlflow --dataset 'reddit_shortcal' --load-from-dir 'data/baseline3' \
--save-results-dir 'results/neurips/reddit_shortcal' --save-check-dir 'checkpoints/neurips/reddit_shortcal' \
--eval-metrics True --include-poisson True --patience 50 --batch-size 10 --split $split \
--encoder 'gru' --encoder-encoding 'temporal_with_labels' --encoder-emb-dim 8 --encoder-embedding-constraint 'nonneg' \
--encoder-units-rnn 32 --encoder-layers-rnn 1 --encoder-constraint-rnn 'nonneg' \
--encoder-units-mlp 16 --encoder-activation-mlp 'relu' --encoder-constraint-mlp 'nonneg' \
--decoder 'mlp-cm' --decoder-encoding 'log_times_only' --decoder-emb-dim 8 --decoder-embedding-constraint 'nonneg' \
--decoder-units-mlp 16 --decoder-units-mlp 16 --decoder-activation-mlp 'gumbel_softplus' \
--decoder-activation-final-mlp 'parametric_softplus' --decoder-constraint-mlp 'nonneg' 
done


##Stack  

for split in {0..2}
do
python3 -u scripts/train2.py --no-mlflow --dataset 'stack_overflow_shortcal' --load-from-dir 'data/baseline3' \
--save-results-dir 'results/neurips/stack_overflow_shortcal' --save-check-dir 'checkpoints/neurips/stack_overflow_shortcal' \
--eval-metrics True --include-poisson True --patience 50 --batch-size 32 --split $split \
--encoder 'gru' --encoder-encoding 'temporal_with_labels' --encoder-emb-dim 8 --encoder-embedding-constraint 'nonneg' \
--encoder-units-rnn 32 --encoder-layers-rnn 1 --encoder-constraint-rnn 'nonneg' \
--encoder-units-mlp 16 --encoder-activation-mlp 'relu' --encoder-constraint-mlp 'nonneg' \
--decoder 'mlp-cm' --decoder-encoding 'log_times_only' --decoder-emb-dim 8 --decoder-embedding-constraint 'nonneg' \
--decoder-units-mlp 16 --decoder-units-mlp 16 --decoder-activation-mlp 'gumbel_softplus' \
--decoder-activation-final-mlp 'parametric_softplus' --decoder-constraint-mlp 'nonneg' 
done

