{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lastfm_filtered\n",
      "mooc_filtered\n",
      "github_filtered\n",
      "retweets_filtered_short\n",
      "reddit_filtered_short\n",
      "stack_overflow_filtered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanguy/miniconda/envs/env_tpp/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ccccccc}\n",
      "\\toprule\n",
      " models & \\multicolumn{6}{c}{NLL-T} \\\\\n",
      "        &            LastFM &             MOOC &            Github &         Retweets &          Reddit &  Stack Overflow \\\\\n",
      "\\midrule\n",
      "STHP-JD & -998.862 (62.428) & -159.064 (3.129) & -228.801 (51.724) & -529.886 (2.854) & -80.787 (2.982) & -82.828 (2.104) \\\\\n",
      "STHP-DD & -1029.144 (45.77) & -159.059 (2.813) &  -260.269 (60.87) & -530.722 (2.597) & -81.101 (3.081) & -82.413 (2.072) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{ccccccc}\n",
      "\\toprule\n",
      " models & \\multicolumn{6}{c}{PCE} \\\\\n",
      "        &        LastFM &          MOOC &        Github &      Retweets &        Reddit & Stack Overflow \\\\\n",
      "\\midrule\n",
      "STHP-JD & 0.295 (0.007) & 0.344 (0.003) & 0.298 (0.032) & 0.153 (0.003) &   0.079 (0.0) &    0.011 (0.0) \\\\\n",
      "STHP-DD & 0.284 (0.006) & 0.344 (0.002) & 0.271 (0.022) & 0.145 (0.002) & 0.075 (0.001) &     0.01 (0.0) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{ccccccc}\n",
      "\\toprule\n",
      " models & \\multicolumn{6}{c}{NLL-M} \\\\\n",
      "        &          LastFM &           MOOC &           Github &       Retweets &         Reddit &  Stack Overflow \\\\\n",
      "\\midrule\n",
      "STHP-JD &  684.7 (14.812) & 81.557 (1.668) &  126.487 (25.84) & 83.054 (0.396) & 44.011 (1.284) & 103.349 (1.063) \\\\\n",
      "STHP-DD & 662.201 (18.74) & 70.579 (1.565) & 118.218 (24.903) & 82.979 (0.433) & 40.552 (1.065) & 102.757 (0.995) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{ccccccc}\n",
      "\\toprule\n",
      " models & \\multicolumn{6}{c}{ECE} \\\\\n",
      "        &        LastFM &          MOOC &        Github &      Retweets &        Reddit & Stack Overflow \\\\\n",
      "\\midrule\n",
      "STHP-JD & 0.076 (0.012) & 0.032 (0.002) &   0.13 (0.01) & 0.057 (0.003) & 0.049 (0.007) &  0.025 (0.001) \\\\\n",
      "STHP-DD & 0.028 (0.001) & 0.013 (0.001) & 0.096 (0.027) & 0.058 (0.001) & 0.017 (0.002) &  0.023 (0.001) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{ccccccc}\n",
      "\\toprule\n",
      " models & \\multicolumn{6}{c}{Acc} \\\\\n",
      "        &        LastFM &          MOOC &        Github &      Retweets &        Reddit & Stack Overflow \\\\\n",
      "\\midrule\n",
      "STHP-JD & 0.233 (0.009) &  0.47 (0.002) & 0.643 (0.016) & 0.612 (0.001) & 0.809 (0.003) &  0.483 (0.001) \\\\\n",
      "STHP-DD &  0.24 (0.014) & 0.557 (0.002) & 0.674 (0.009) & 0.612 (0.001) & 0.819 (0.002) &  0.485 (0.001) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{ccccccc}\n",
      "\\toprule\n",
      " models & \\multicolumn{6}{c}{Acc@3} \\\\\n",
      "        &       LastFM &          MOOC &        Github &  Retweets &        Reddit & Stack Overflow \\\\\n",
      "\\midrule\n",
      "STHP-JD & 0.39 (0.009) & 0.785 (0.001) & 0.874 (0.009) & 1.0 (0.0) & 0.892 (0.004) &  0.825 (0.001) \\\\\n",
      "STHP-DD & 0.41 (0.013) & 0.821 (0.001) & 0.887 (0.005) & 1.0 (0.0) & 0.902 (0.002) &  0.826 (0.001) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{ccccccc}\n",
      "\\toprule\n",
      " models & \\multicolumn{6}{c}{Acc@5} \\\\\n",
      "        &        LastFM &          MOOC &        Github &  Retweets &        Reddit & Stack Overflow \\\\\n",
      "\\midrule\n",
      "STHP-JD & 0.483 (0.011) & 0.887 (0.002) & 0.967 (0.002) & 1.0 (0.0) & 0.919 (0.004) &  0.926 (0.001) \\\\\n",
      "STHP-DD & 0.511 (0.011) & 0.904 (0.001) & 0.969 (0.002) & 1.0 (0.0) & 0.928 (0.002) &    0.926 (0.0) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{ccccccc}\n",
      "\\toprule\n",
      " models & \\multicolumn{6}{c}{Acc@10} \\\\\n",
      "        &        LastFM &          MOOC &    Github &  Retweets &        Reddit & Stack Overflow \\\\\n",
      "\\midrule\n",
      "STHP-JD &  0.63 (0.012) & 0.964 (0.001) & 1.0 (0.0) & 1.0 (0.0) & 0.953 (0.002) &    0.988 (0.0) \\\\\n",
      "STHP-DD & 0.657 (0.007) & 0.969 (0.001) & 1.0 (0.0) & 1.0 (0.0) &  0.96 (0.001) &    0.988 (0.0) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{ccccccc}\n",
      "\\toprule\n",
      " models & \\multicolumn{6}{c}{MRR} \\\\\n",
      "        &        LastFM &          MOOC &        Github &      Retweets &        Reddit & Stack Overflow \\\\\n",
      "\\midrule\n",
      "STHP-JD &  0.36 (0.009) & 0.646 (0.001) & 0.772 (0.011) & 0.799 (0.001) & 0.859 (0.002) &  0.672 (0.001) \\\\\n",
      "STHP-DD & 0.373 (0.012) & 0.704 (0.001) & 0.793 (0.006) &   0.799 (0.0) & 0.869 (0.001) &  0.673 (0.001) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{ccccccc}\n",
      "\\toprule\n",
      " models & \\multicolumn{6}{c}{F1-score} \\\\\n",
      "        &        LastFM &          MOOC &       Github &      Retweets &        Reddit & Stack Overflow \\\\\n",
      "\\midrule\n",
      "STHP-JD & 0.224 (0.007) & 0.453 (0.001) & 0.58 (0.015) & 0.599 (0.001) & 0.802 (0.004) &    0.346 (0.0) \\\\\n",
      "STHP-DD & 0.234 (0.014) & 0.545 (0.001) & 0.61 (0.008) &   0.6 (0.001) & 0.812 (0.001) &  0.351 (0.001) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/bdml1/tanguy/icml/plot/tabulars.py:832: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df_tex = df.to_latex(index=False, escape=False, multicolumn_format='c', column_format=columns)\n",
      "/ssd/bdml1/tanguy/icml/plot/tabulars.py:832: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df_tex = df.to_latex(index=False, escape=False, multicolumn_format='c', column_format=columns)\n",
      "/ssd/bdml1/tanguy/icml/plot/tabulars.py:832: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df_tex = df.to_latex(index=False, escape=False, multicolumn_format='c', column_format=columns)\n",
      "/ssd/bdml1/tanguy/icml/plot/tabulars.py:832: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df_tex = df.to_latex(index=False, escape=False, multicolumn_format='c', column_format=columns)\n",
      "/ssd/bdml1/tanguy/icml/plot/tabulars.py:832: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df_tex = df.to_latex(index=False, escape=False, multicolumn_format='c', column_format=columns)\n",
      "/ssd/bdml1/tanguy/icml/plot/tabulars.py:832: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df_tex = df.to_latex(index=False, escape=False, multicolumn_format='c', column_format=columns)\n",
      "/ssd/bdml1/tanguy/icml/plot/tabulars.py:832: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df_tex = df.to_latex(index=False, escape=False, multicolumn_format='c', column_format=columns)\n",
      "/ssd/bdml1/tanguy/icml/plot/tabulars.py:832: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df_tex = df.to_latex(index=False, escape=False, multicolumn_format='c', column_format=columns)\n",
      "/ssd/bdml1/tanguy/icml/plot/tabulars.py:832: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df_tex = df.to_latex(index=False, escape=False, multicolumn_format='c', column_format=columns)\n",
      "/ssd/bdml1/tanguy/icml/plot/tabulars.py:832: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  df_tex = df.to_latex(index=False, escape=False, multicolumn_format='c', column_format=columns)\n"
     ]
    }
   ],
   "source": [
    "from plot.tabulars import get_test_loss_results_v4\n",
    "\n",
    "   \n",
    "models_thp = [\n",
    "    'gru_thp_temporal_with_labels_adjust_param',\n",
    "    'gru_thp-jd_temporal_with_labels_adjust_param',\n",
    "    #'gru_temporal_with_labels_gru_temporal_with_labels_sep-thp-mix_separate_ind',\n",
    "    'gru_temporal_with_labels_gru_temporal_with_labels_thp-dd_separate'\n",
    "]\n",
    "\n",
    "models_sa_thp = [\n",
    "    'selfattention_thp_temporal_with_labels_adjust_param',\n",
    "    'selfattention_thp-jd_temporal_with_labels_adjust_param',\n",
    "    #'gru_temporal_with_labels_gru_temporal_with_labels_sep-thp-mix_separate_ind',\n",
    "    'selfattention_temporal_with_labels_selfattention_temporal_with_labels_thp-dd_separate'\n",
    "]\n",
    "\n",
    "\n",
    "models_sahp = [\n",
    "    'gru_sahp_temporal_with_labels_adjust_param',\n",
    "    'gru_sahp-jd_temporal_with_labels_adjust_param',\n",
    "    #'gru_temporal_with_labels_gru_temporal_with_labels_sep-sahp-mix_separate_ind',\n",
    "    'gru_temporal_with_labels_gru_temporal_with_labels_sahp-dd_separate'\n",
    "]\n",
    "\n",
    "models_sa_sahp = [\n",
    "    #Waiting for remaining runs \n",
    "    'selfattention_sahp_temporal_with_labels_adjust_param',\n",
    "    'selfattention_sahp-jd_temporal_with_labels_adjust_param',\n",
    "    #'gru_temporal_with_labels_gru_temporal_with_labels_sep-sahp-mix_separate_ind',\n",
    "    'selfattention_temporal_with_labels_selfattention_temporal_with_labels_sahp-dd_separate'\n",
    "]\n",
    "\n",
    "models_fnn = [\n",
    "    'poisson_gru_mlp-cm_temporal_with_labels_adjust_param',\n",
    "    'poisson_gru_mlp-cm-jd_temporal_with_labels_adjust_param',\n",
    "    #'gru_temporal_with_labels_gru_temporal_with_labels_sep-mlp-cm-mix_separate_ind_base',\n",
    "    'poisson_gru_temporal_with_labels_gru_temporal_with_labels_mlp-cm-dd_separate',\n",
    "]\n",
    "\n",
    "models_sa_fnn = [\n",
    "    'poisson_selfattention_mlp-cm_temporal_with_labels_adjust_param',\n",
    "    'poisson_selfattention_mlp-cm-jd_temporal_with_labels_adjust_param',\n",
    "    #'gru_temporal_with_labels_gru_temporal_with_labels_sep-mlp-cm-mix_separate_ind_base',\n",
    "    'poisson_selfattention_temporal_with_labels_selfattention_temporal_with_labels_mlp-cm-dd_separate',\n",
    "]\n",
    "\n",
    "models_lnm = [\n",
    "    'gru_log-normal-mixture_temporal_with_labels_adjust_param',\n",
    "    'gru_log-normal-mixture-jd_temporal_with_labels_adjust_param',\n",
    "    'gru_temporal_with_labels_gru_temporal_with_labels_log-normal-mixture-dd_separate'\n",
    "]\n",
    "\n",
    "models_sa_lnm = [\n",
    "    'selfattention_log-normal-mixture_temporal_with_labels_adjust_param',\n",
    "    'selfattention_log-normal-mixture-jd_temporal_with_labels_adjust_param',\n",
    "    'selfattention_temporal_with_labels_selfattention_temporal_with_labels_log-normal-mixture-dd_separate'\n",
    "]\n",
    "\n",
    "models_lnm_joint = [\n",
    "    #'gru_log-normal-mixture-jd_temporal_with_labels_adjust_param',\n",
    "    'gru_joint-log-normal-mixture_temporal_with_labels_adjust_param'\n",
    "]\n",
    "\n",
    "models_rmtpp = [\n",
    "    'gru_rmtpp_temporal_with_labels_adjust_param',\n",
    "    'gru_rmtpp-jd_temporal_with_labels_adjust_param',\n",
    "    'gru_temporal_with_labels_gru_temporal_with_labels_rmtpp-dd_separate',\n",
    "]\n",
    "\n",
    "models_sa_rmtpp = [\n",
    "    'selfattention_rmtpp_temporal_with_labels_adjust_param',\n",
    "    'selfattention_rmtpp-jd_temporal_with_labels_adjust_param',\n",
    "    'selfattention_temporal_with_labels_selfattention_temporal_with_labels_rmtpp-dd_separate',\n",
    "]\n",
    "\n",
    "models_hawkes = [\n",
    "    'stub_hawkes_times_only_check_evaluation'\n",
    "]\n",
    "\n",
    "models_smurf_thp = [\n",
    "    'gru_smurf-thp-jd_temporal_with_labels_adjust_param',\n",
    "    'gru_temporal_with_labels_gru_temporal_with_labels_smurf-thp-dd_separate'\n",
    "]\n",
    "\n",
    "#datasets_marked = ['lastfm_filtered', 'mooc_filtered', 'github_filtered',  'retweets_filtered_short', 'reddit_filtered_short']\n",
    "datasets_marked = ['lastfm_filtered', 'mooc_filtered', 'github_filtered',  'retweets_filtered_short', 'reddit_filtered_short', 'stack_overflow_filtered']\n",
    "#datasets_marked = ['lastfm_filtered']\n",
    "\n",
    "models = models_thp + models_sahp + models_lnm + models_rmtpp\n",
    "models = models_fnn\n",
    "models = models_lnm_joint\n",
    "models = models_smurf_thp\n",
    "#models = models_sa_thp +models_sa_sahp + models_sa_lnm + models_sa_rmtpp + models_sa_fnn\n",
    "\n",
    "results_dir = 'results/icml'\n",
    "\n",
    "get_test_loss_results_v4(results_dir, datasets_marked, models, result_type='marked', n_s=3, to_rank=False, per_dataset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "def show_results(model_name):\n",
    "    path = f'results/simulations/hawkes_exponential_mutual_large_{model_name}.txt'\n",
    "    with open(path, 'rb') as f:\n",
    "        results = pkl.load(f)\n",
    "    marked = results['marked']\n",
    "    ground = results['ground']\n",
    "    print(model_name)\n",
    "    print(f'Marked : {marked}')\n",
    "    print(f'Ground : {ground}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru_thp_temporal_with_labels_adjust_param_nodiv\n",
      "Marked : [0.2787935171601589, 0.383443403659168, 0.2575221046010859, 0.4222071161317638, 0.34597202350495565]\n",
      "Ground : 1.1886118969466422\n",
      "\n",
      "gru_temporal_with_labels_gru_temporal_with_labels_thp-dd_separate_nodiv\n",
      "Marked : [0.1618417307698282, 0.2582201765660488, 0.16566489688963626, 0.27556360184173867, 0.2820121472651847]\n",
      "Ground : 0.9527665084870547\n",
      "\n",
      "gru_sahp_temporal_with_labels_adjust_param\n",
      "Marked : [0.24899860283876188, 0.3068517869028325, 0.2472784301629543, 0.3341490800884883, 0.2993278848698932]\n",
      "Ground : 0.9763474334996701\n",
      "\n",
      "gru_temporal_with_labels_gru_temporal_with_labels_sahp-dd_separate\n",
      "Marked : [0.22038567962219777, 0.2568134941806336, 0.2313464089350457, 0.28620743917853997, 0.2684167795263486]\n",
      "Ground : 0.9230886606874762\n",
      "\n",
      "poisson_gru_mlp-cm_temporal_with_labels_adjust_param\n",
      "Marked : [0.2713562165901267, 0.4006821897995817, 0.2595377503371468, 0.3385375343778109, 0.3025989280558997]\n",
      "Ground : 1.241620813480871\n",
      "\n",
      "poisson_gru_temporal_with_labels_gru_temporal_with_labels_mlp-cm-dd_separate\n",
      "Marked : [0.17364026220599432, 0.22348841686106413, 0.1515380135094315, 0.230490329007458, 0.1957979920623632]\n",
      "Ground : 0.8266107035168102\n",
      "\n",
      "gru_log-normal-mixture_temporal_with_labels_adjust_param\n",
      "Marked : [0.2819793298433626, 0.3719022217953612, 0.2474220739644534, 0.3968938641500079, 0.3955102299836347]\n",
      "Ground : 1.365431972046094\n",
      "\n",
      "gru_temporal_with_labels_gru_temporal_with_labels_log-normal-mixture-dd_separate\n",
      "Marked : [0.16862319711695195, 0.24993562451423812, 0.14538661724348287, 0.2539672355593207, 0.26849368300007687]\n",
      "Ground : 0.9454988936362675\n",
      "\n",
      "gru_rmtpp_temporal_with_labels_adjust_param\n",
      "Marked : [0.2605102048621271, 0.3101190512941922, 0.24468021518567987, 0.4001708758119087, 0.34273878940690494]\n",
      "Ground : 1.1205435624035784\n",
      "\n",
      "gru_temporal_with_labels_gru_temporal_with_labels_rmtpp-dd_separate\n",
      "Marked : [0.20951445249651784, 0.3002575130360377, 0.18996123516222962, 0.33645176655538966, 0.3184257466832509]\n",
      "Ground : 1.1857036447417184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models=[\n",
    "    'gru_thp_temporal_with_labels_adjust_param_nodiv',\n",
    "    'gru_temporal_with_labels_gru_temporal_with_labels_thp-dd_separate_nodiv',\n",
    "\n",
    "    'gru_sahp_temporal_with_labels_adjust_param',\n",
    "    'gru_temporal_with_labels_gru_temporal_with_labels_sahp-dd_separate',\n",
    "\n",
    "    'poisson_gru_mlp-cm_temporal_with_labels_adjust_param',\n",
    "    'poisson_gru_temporal_with_labels_gru_temporal_with_labels_mlp-cm-dd_separate',\n",
    "\n",
    "    'gru_log-normal-mixture_temporal_with_labels_adjust_param',\n",
    "    'gru_temporal_with_labels_gru_temporal_with_labels_log-normal-mixture-dd_separate',\n",
    "\n",
    "    'gru_rmtpp_temporal_with_labels_adjust_param',\n",
    "    'gru_temporal_with_labels_gru_temporal_with_labels_rmtpp-dd_separate'\n",
    "]\n",
    "for model in models: \n",
    "    show_results(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tpp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
